---
title: "SCCS Simulation"
format: 
  html:
    toc: true
    toc-depth: 3  
    toc-location: left  
editor: visual
---

```{r include=FALSE, message = FALSE}
#Load packages and data
if (!require("pacman", quietly = TRUE)) {
install.packages("pacman")
}
library(pacman)
pacman::p_load(
              foreach,     # foreach loop
              stats,
              tidyverse,
              panelr,      # Reshape data
              SCCS,
              doParallel,
              tictoc,      # Measure performance time
              progressr,   # Measure progress
              rio,         # Export file  
              here,
              data.table,
              magrittr,     # To use the pipe %>%
              doRNG         # Reproducible parallel session
              ) 

options(scipen = 999)
```

## 1. Simple SCCS

### Data generating mechanism

-   Design: SCCS (thus only subjects with outcome are included)
-   Sample size: 1000 cases
-   Observation period: 500 days for all individuals
-   Length of risk period following exposure: 7 or 28 days
-   Control period = Observation period minus risk period
-   True direct effect of E (exposure) on Y (outcome): $IRR = e^\beta = 1, 2 or 5$
-   Baseline rate of the event: $exp(\psi_i) = 1*10^{-5}$, thus the event is rare and no more than 1% of cases having \>1 event during the observation period

Procedure to generate data:

1.  Fix parameter values and random seed

2.  Generate exposure date. Then the observation time is partitioned into risk and control period, with $e_{ik}$ number of day subject $i$ spends in period $k$

3.  Generate the marginal total number of events per subject, using a zero-truncated Poisson distribution with rate $\Sigma_{k=0}^{1}\lambda_{ik}e_{ik} =\Sigma_{k=0}^{2}exp[\psi_i + \beta k]e_{ik}$, conditionally on the exposure history.

4.  Use multinomial distribution to randomly allocate each event with the probability $\frac{\lambda_{ik}e_{ik}}{\Sigma_{k=0}^1\lambda_{ik}e_{ik}}$ to the risk/ control period for each subject

5.  Fit the SCCS model (Conditional Poisson regression) to estimate the IRR & their 95% CI of the effect of E on Y

6.  Repeat the step 2 to 5 to conduct 10000 replicates of the simulation

7.  Output the results: 1) the pooled IRR 2) Percentage of bias compared to the true IRR 3) Empirical standard error 4) Coverage of CI.

#### Function to generate SCCS data

```{r}
simple_sccs_data <- function(n = 1000, obs_time = 500, baseline_rate = 1e-5, beta=log(2), risk_length=28)
{
  dataset <- data.frame()
  
  for (i in 1:n)
  {
    # Generate exposure time
    exposure_start <- sample(1:(obs_time - risk_length), 1) #date of exposure
    exposure_end <- exposure_start + risk_length - 1        
    lambda0 <- baseline_rate
    lambda1 <- baseline_rate * exp(beta)
    
    e0 <- obs_time - risk_length #length control window
    e1 <- risk_length
    mu <- lambda0 * e0 + lambda1 * e1 #event rate
    
    # Generate marginal total number of events per subject, at least 1 event
    total_events <- rtpois(1, lambda = mu, a = 0) 
    
    # Allocate event to risk/control period
    p0 <- (lambda0 * e0) / mu
    p1 <- (lambda1 * e1) / mu
    allocation <- rmultinom(1, total_events, prob = c(p0, p1)) 
    n0 <- allocation[1] #nr event in control period
    n1 <- allocation[2] #nr event in risk period
    
    event_days_0 <- if (n0 > 0) sample(setdiff(1:obs_time, exposure_start:exposure_end), n0, replace = TRUE) else numeric(0)
    event_days_1 <- if (n1 > 0) sample(exposure_start:exposure_end, n1, replace = TRUE) else numeric(0)
    event_days <- sort(c(event_days_0, event_days_1))
    
    # Generate observation for each subject
    indiv_df <- data.frame(
    indiv = rep(i, length(event_days)),
    eventday = event_days,
    expostart = rep(exposure_start, length(event_days)),
    expoend = rep(exposure_end, length(event_days)),
    obs_start = 1,
    obs_end = obs_time
    )
      
    dataset <- bind_rows(dataset, indiv_df)
  }
  
  return(dataset)
}
```

### Data analysis

#### Function to analyse dataset

```{r}
analyse_sccs_simple <- function(df, rep)
  {

  # Fit SCCS model
  model <- standardsccs(event ~ expostart, 
                       indiv= indiv,      # subject ID
                       astart = obs_start,# start of observation period 
                       aend = obs_end,    # end of observation period 
                       aevent = eventday, # event time
                       adrug = expostart, # start of exposure
                       aedrug = expoend,  # end of risk period
                       expogrp = 0,       # start of risk period counted from 'adrug'
                       data = df)
  
  # Extract results from SCCS model
  est <- coef(model)[1,1]
  se <- coef(model)[1,3]
  IRR <- exp(est)
  IRR_CI_Lower <- model$conf.int[,3]
  IRR_CI_Upper <- model$conf.int[,4]
  n_event <- model$nevent
  res <- data.frame(rep = rep, est, se, IRR, IRR_CI_Lower, IRR_CI_Upper, n_event, row.names = NULL)
  return(res)
}
```

#### Function to loop simulation

Small number of iterations to check if it works:

```{r}
set.seed(1003)

n_sim <- 5

tic("Serial simulation")
rng_states_serial <- list() #Store the state of the random number generator 

results <- foreach( i = 1:n_sim, .combine="rbind") %do% {
  rng_states_serial[[i]] <- .Random.seed  # save RNG state
  data <- simple_sccs_data(n = 1000, obs_time = 500, baseline_rate = 1e-5, beta=log(2), risk_length=28)
  result<-analyse_sccs_simple(data, i)
}
toc()
# view results
head(results)

```

##### Parallel session

Still has not run properly

```{r eval=FALSE}
set.seed(1003)
n_sim <- 5

tic("Parallel simulation") # measure run time
# Set up parallel sessions
n_cores <- parallel::detectCores() - 1
cl <- makeCluster(n_cores)
registerDoParallel(cl)
RNGkind("L'Ecuyer-CMRG")  # for parallel-safe reproducibility

results_list <- foreach(i = 1:n_sim, 
                        .packages = c("extraDistr", "dplyr", "SCCS")) %dopar% {
  seed <- .Random.seed 
  data <- simple_sccs_data(n = 1000, obs_time = 500, baseline_rate = 1e-5, beta = log(2), risk_length = 28)
  result <- analyse_sccs_simple(data, i)
  
  list(result = result, seed = seed) 
}

stopCluster(cl)
toc() # measure run time

results_df <- bind_rows(lapply(results_list, function(x) x$result))
rng_states_parallel <- lapply(results_list, function(x) x$seed)
names(rng_states) <- paste0("rep", seq_along(rng_states))
```

### Function to quantify bias and measure performance

```{r}


bias_quantification <- function(true_IRR = 2, result_table)
{
  true_beta1 = log(true_IRR)

  # Number of missing values of estimated beta1 (e.g due to convergence)
  missing_beta1 <- sum(is.na(result_table$est))
  
  # bias
  beta_hat <- mean(result_table[,"est"])
  bias <- beta_hat - true_beta1
  
  # Coverage
  result_table$coverage_IRR <- with(result_table,
                                    IRR_CI_Lower <= true_IRR & IRR_CI_Upper >= true_IRR)
  coverage_irr <- mean(result_table$coverage_IRR)
  
  performance <- data.frame(missing_beta1, bias, coverage_irr)
  
}
```

## Check the simulation

### Simulate and analyse a single set of data

```{r}
set.seed(100)
data_test <- simple_sccs_data(n = 1000, obs_time = 500, baseline_rate = 1e-5, beta=log(2), risk_length=28)

result_test <- analyse_sccs_simple(data_test,1)
result_test
```

### Recreate a Specific Dataset Using a Stored RNG State

```{r}
.Random.seed <- rng_states[[6]]
data_6 <- simple_sccs_data(n = 1000, obs_time = 500, baseline_rate = 1e-5, beta=log(2), risk_length=28)
result_test2 <- analyse_sccs_simple(data_6, 1)
result_test2
```

## 2. Cohort data generating procedure

1.  Generate a cohort of 100,000 individuals (to get at least 1000 events)
2.  Generate observation time: 500 for all individuals
3.  Generate binary exposure (vaccination) for 80% of the individuals
    -   Date of exposure (for those with the exposure present): random variable from a uniform distribution within each individuals' observation period
    -   Risk window length: 28 days post-exposure
4.  Binary outcome: generated as a function of baseline event odds ($\beta_0$) and exposure status ($\beta_1$). The daily odds of the outcome on day $j$ during the observation period of individual $i$ is calculated from the logistic regression model:

$$Logit[Pr(Y_{ij} = 1)] = \beta_0 + \beta_1*Exposure_{ij}$$

-   Set $\beta_0 = ln(2e-5), \beta_1 = ln(2)$ (Outcome is rare and being exposed increase the odds of the outcome 2 times)
-   Based on the daily probability, generate the binary outcome using a Bernoulli trial
-   Each subjects could have multiple (independent) outcomes during the observation period, but with very low probability

```{r}
simple_sccs_data2 <- function(n = 100000, obs_time = 500, baseline_odds = 2e-5, IRR = 2, risk_length=28)
{
  beta0 <- log(baseline_odds)   
  beta1 <- log(IRR)
  
  dataset <- data.frame()
  
    # Assign exposure status
    exposed <- rbinom(n, 1, 0.8)
    # If exposed, assign exposure date
    exposure_start <- rep(NA, n)
    exposure_start[exposed == 1] <- sample(1:(obs_time - risk_length), 
                                           sum(exposed), replace = TRUE)
    exposure_end <- exposure_start + risk_length - 1
    
    # Expand the data to long format: one row per individual per day
    id <- rep(1:n, each = obs_time)
    day <- rep(1:obs_time, times = n)
    
    # Daily exposure status
    exposure_start_long <- rep(exposure_start, each = obs_time)
    exposure_end_long <- rep(exposure_end, each = obs_time)
    exposure_status <- ifelse(!is.na(exposure_start_long) & day >= exposure_start_long & day <= exposure_end_long, 1, 0)
    # Daily outcome status
    logit_p <- beta0 + beta1 * exposure_status
    p_event <- plogis(logit_p)
    outcome <- rbinom(length(p_event), 1, p_event)
    
    # Long data format
  long_data <- data.frame(
    id = id,
    day = day,
    exposure = exposure_status,
    outcome = outcome,
    exposure_start = exposure_start_long,
    exposure_end = exposure_end_long
  )

  # Keep only event days
  event_data <- subset(long_data, outcome == 1 & !is.na(exposure_start_long))
  
  # SCCS data format
    sccs_data <- data.frame(
    indiv = event_data$id,
    obs_start = 1,
    obs_end = obs_time,
    expostart = event_data$exposure_start,
    expoend = event_data$exposure_end,
    eventday = event_data$day
  )
  
  return(sccs_data)
}
```

### Test the data-generating mechanism

Test one run using different seeds

```{r}
set.seed(123)
tic("Analyse 1 dataset")
data_test2 <- simple_sccs_data2(n = 100000, obs_time = 500, baseline_odds = 2e-5, IRR = 5, risk_length=28)
mean(data_test2$eventday<= data_test2$expostart + 27 & data_test2$eventday >= data_test2$expostart )*100

result_test <- analyse_sccs_simple(data_test2,1)
result_test
toc()

set.seed(1003)
tic("Analyse 1 dataset")
data_test <- simple_sccs_data2(n = 100000, obs_time = 500, baseline_odds = 2e-5, IRR = 2, risk_length=28)

result_test <- analyse_sccs_simple(data_test,1)
result_test
toc()

set.seed(200)
tic("Analyse 1 dataset")
data_test <- simple_sccs_data2(n = 100000, obs_time = 500, baseline_odds = 2e-5, IRR = 2, risk_length=28)

result_test <- analyse_sccs_simple(data_test,1)
result_test
toc()

set.seed(1280)
tic("Analyse 1 dataset")
data_test <- simple_sccs_data2(n = 100000, obs_time = 500, baseline_odds = 2e-5, IRR = 2, risk_length=28)

result_test <- analyse_sccs_simple(data_test,1)
result_test
toc()
```

Check with small number of runs

```{r}
set.seed(1003)

n_sim <- 10

tic("Cohort simulation")
rng_states <- list() #Store the state of the random number generator 

results <- foreach( i = 1:n_sim, .combine="rbind") %do% {
  rng_states[[i]] <- .Random.seed  # save RNG state
  data <- simple_sccs_data2(n = 100000, obs_time = 500, baseline_odds = 2e-5, IRR = 2, risk_length=28)
  result<-analyse_sccs_simple(data, i)
}
toc()

```

### Run the full simulation

```{r}
set.seed(2025)

n_sim <- 1000
#handlers(global = TRUE)  # Need to run this code in the console instead or RMarkdown

tic("Cohort simulation")
rng_states <- list() #Store the state of the random number generator 

with_progress({
  p <- progressor(steps = n_sim)

results_1000 <- foreach( i = 1:n_sim, .combine="rbind") %do% {
  p(sprintf("Iteration %d", i))  # update progress
  rng_states[[i]] <- .Random.seed  # save RNG state
  data <- simple_sccs_data2(n = 100000, obs_time = 500, baseline_odds = 2e-5, IRR = 2, risk_length=28)
  result<-analyse_sccs_simple(data, i)
}
})
toc() #2.5h to complete the simulation

#export(results_1000, here("Results", "SCCS_results_no_confounder.csv"))
#capture.output(rng_states, file = "RNG_states_SCCS_no_confounder.txt")

# Evaluate performance

#Exploratory
#Distribution of effect estimates

hist(results_1000$est, breaks = 30, main = "Distribution of beta_1")
hist(results_1000$se, breaks = 30, main = "Distribution of SE of beta_1")
hist(results_1000$n_event, breaks = 10, main = "Distribution of number of events")

bias_quantification_result <-bias_quantification(result_table = results_1000)
bias_quantification_result <- bias_quantification_result %>%
  mutate(mean_nr_event = mean(results_1000$n_event))
bias_quantification_result
```

## 3. Cohort - daily exposure status

-   Cohort of 100,000 individual
-   Daily odds of exposure E (vaccination): $3.2*10^{-3}$ (so that 80% of the sample get vaccinated within 500 days). Once the subject got vaccinated, odds of next vaccination reduces by 99.9%.

### Function: Generate data

```{r}
cohort <-function(n = 100000, obs_time = 500, risk_window=28, 
                               p_E = 3.2e-3,E_reduce_E = 0.001,
                               baseline_Y = 2e-5, IRR_E = 2)
{
  log_p_E <- log(p_E)
  log_E_reduce_E <- log(E_reduce_E)
  log_baseline_Y <- log(baseline_Y)
  log_IRR_E <- log(IRR_E)

E <- matrix(0L, nrow = n, ncol = obs_time)
Y <- matrix(0L, nrow = n, ncol = obs_time)


# Rolling sum of history of E

roll_E_onE <- integer (n)
roll_E_onY <- integer (n)


  for (t in 1:obs_time) {
# Remove  E events that fall outside the look-back window

    if (t > risk_window) {
      roll_E_onY <- roll_E_onY - E[, t - risk_window]
    }

    # Generate E (depends on  previous E)
    recent_E_onE <- roll_E_onE > 0
    prob_E <- plogis(log_p_E + log_E_reduce_E*recent_E_onE)
    E_t <- rbinom(n, 1, prob_E)
    E[, t] <- E_t
    
    # Update rolling of E
    roll_E_onE <- roll_E_onE + E_t
    roll_E_onY <- roll_E_onY + E_t
    
    
    # Generate Y (depends on E[t-risk_window+1, t])
    recent_E_onY <- roll_E_onY > 0
    prob_Y <- plogis(log_baseline_Y + log_IRR_E*recent_E_onY)
    Y[, t] <- rbinom(n, 1, prob_Y)
    
  }

# Reshape to long format
id <- rep(1:n, each = obs_time)
day <- rep(1:obs_time, times = n)
data_long <- data.frame(
  id = id,
  day = day,
  E = as.vector(t(E)),
  Y = as.vector(t(Y))
)
data_long <- as.data.table(data_long)

return(data_long)
}
```

### Function: Reshape data to SCCS-compatible format

```{r}
SCCS_reformat <- function(data){
  Y_data <- data[Y ==1 , .(id, Y_day = day)]
  Y_data <- Y_data[, .row := seq_len(.N), by = id]
  E_data <- data[E ==1 , .(id, E_day = day)]
  E_data <- E_data[, .row := seq_len(.N), by = id]

  merge_Y_E <- merge(Y_data, E_data, by = c("id"), all = TRUE)
  merge_Y_E2 <- merge_Y_E[!is.na(Y_day) & !is.na(E_day)]
  merge_Y_E2 <- merge_Y_E2[ , `:=`(obs_start = 1, obs_end = 500)]
  merge_Y_E2 <- as.data.frame(merge_Y_E2)

  return(merge_Y_E2)
}
```

### Funtion: Analyse data

```{r}
analyse_SCCS <- function(data, risk_window = 28, rep=1){

  model <- standardsccs(event ~ E_day, 
                       indiv= id,      # subject ID
                       astart = obs_start,# start of observation period 
                       aend = obs_end,    # end of observation period 
                       aevent = Y_day, # event time
                       adrug = E_day, # start of exposure
                       aedrug = E_day + risk_window - 1,  # end of risk period
                       expogrp = 0,       # start of risk period counted from 'adrug'
                       data = data)
 # Extract results from SCCS model
  est <- coef(model)[1,1]
  se <- coef(model)[1,3]
  IRR <- exp(est)
  IRR_CI_Lower <- model$conf.int[,3]
  IRR_CI_Upper <- model$conf.int[,4]
  n_event <- model$nevent
  res <- data.frame(rep = rep, est, se, IRR, IRR_CI_Lower, IRR_CI_Upper, n_event, row.names = NULL)
  return(res)
}
```

### Test the functions

```{r}
set.seed(1003)
tic("Cohort simulation long format")
test <- cohort() 
toc()
test_reformatted <- SCCS_reformat(test)
analyse_SCCS(data = test_reformatted)
```

### Run the full simulation

```{r}
set.seed(2025)

n_sim <- 1000
#handlers(global = TRUE)  # Need to run this code in the console instead or RMarkdown

tic("Cohort simulation")
rng_states <- list() #Store the state of the random number generator 

with_progress({
  p <- progressor(steps = n_sim)

cohort_1000 <- foreach( i = 1:n_sim, .combine="rbind") %do% {
  p(sprintf("Iteration %d", i))  # update progress
  rng_states[[i]] <- .Random.seed  # save RNG state
  data <- cohort(n = 100000, obs_time = 500, risk_window=28, 
                               p_E = 3.2e-3,E_reduce_E = 0.001,
                               baseline_Y = 2e-5, IRR_E = 3)
  data_SCCS <- SCCS_reformat(data)
  result<-analyse_SCCS(data= data_SCCS, risk_window = 28, rep = i)
  result
}
})
toc()

#export(cohort_1000, here("Results", "SCCS_results_no_confounder_daily.csv"))
#capture.output(rng_states, file = "RNG_states_SCCS_no_confounder_daily.txt")

# Evaluate performance

#Exploratory
#Distribution of effect estimates

hist(cohort_1000$est, breaks = 30, main = "Distribution of beta_1")
hist(cohort_1000$se, breaks = 30, main = "Distribution of SE of beta_1")
hist(cohort_1000$n_event, breaks = 10, main = "Distribution of number of events")

bias_quantification_result <-bias_quantification(true_IRR = 3, result_table = cohort_1000)
bias_quantification_result <- bias_quantification_result %>%
  mutate(mean_nr_event = mean(cohort_1000$n_event))
bias_quantification_result
```

## 4. Time-varying confounder

### Function: Generate data

-   Cohort of 100,000 individual

-   Daily odds of the binary time-varying confounder C (COVID-19 infection): $10^{-3}$. Being infected within 90 days reduce that odds by 70%. Based on the daily probability, generate the binary time-varying confounder using a Bernoulli trial.

-   Daily odds of exposure E (vaccination): $3.2*10^{-3}$ (so that 80% of the sample get vaccinated within 500 days). Once the subject got vaccinated, odds of next vaccination reduces by 99.9% Getting infected on that day and previous 27 days reduces the odds by 75%.

-   Duration of effect of C and E on binary outcome Y: 28 days including day 0.

-   Y is generated as a function of baseline event odds ($\beta_0$), exposure status ($\beta_1$) and Confounder status ($\beta_2$). The daily odds of the outcome on day $j$ during the observation period of individual $i$ is calculated from the logistic regression model:

$$Logit[Pr(Y_{ij} = 1)] = \beta_0 + \beta_1*E_{ij} + \beta_2*C_{ij}$$

-   Set $\beta_0 = ln(2e-5), \beta_1 = ln(2), \beta_2 = ln(5)$ (Outcome is rare and being exposed/ having counfounder increases the odds of the outcome 2 times and 5 times, respectively)
-   Based on the daily probability, generate the binary outcome using a Bernoulli trial
-   Each subjects could have multiple (independent) outcomes during the observation period, but with very low probability

```{r}
cohort_time_varying <-function(n = 100000, obs_time = 500, risk_window = chosen_risk_window, 
                               p_C = 1e-3, C_reduce_C = 0.3, 
                               p_E = 3.2e-3, C_reduce_E = 0.25, E_reduce_E = 0.001,
                               baseline_Y = 2e-5, IRR_E = 2, IRR_C = 5)
{
  log_p_C <- log(p_C)
  log_p_E <- log(p_E)
  log_C_reduce_C <- log(C_reduce_C)
  log_C_reduce_E <- log(C_reduce_E)
  log_E_reduce_E <- log(E_reduce_E)
  log_baseline_Y <- log(baseline_Y)
  log_IRR_E <- log(IRR_E)
  log_IRR_C <- log(IRR_C)    

C <- matrix(0L, nrow = n, ncol = obs_time)
E <- matrix(0L, nrow = n, ncol = obs_time)
Y <- matrix(0L, nrow = n, ncol = obs_time)

# Rolling sum of history of C and E
roll_C_onC <- integer(n)
roll_C_onE <- integer(n)
roll_E_onE <- integer(n)
roll_C_onY <- integer(n)
roll_E_onY <- integer(n)


  for (t in 1:obs_time) {
# Remove C or E events that fall outside the look-back window (28 days for C on E, C on Y, E on Y, and 91 days for C on C)
    if (t > 28) {
      roll_C_onE <- roll_C_onE - C[, t- 28]
    }
    if (t > risk_window) {
      roll_C_onY <- roll_C_onY - C[, t - risk_window]
      roll_E_onY <- roll_E_onY - E[, t - risk_window]
    }
    if (t > 91) {
      roll_C_onC <- roll_C_onC - C[, t - 91]
    # roll_E_onE <- roll_E_onE - E[, t - 91]  # Deactivate this because the look-back window for E on E is the whole observation period
    }

    # Generate C (depends on C[t-90, t-1])
    recent_C_onC <- roll_C_onC > 0 # Check recent history of C
    prob_C <- plogis(log_p_C + log_C_reduce_C*recent_C_onC)
    C_t <- rbinom(n, 1, prob_C)
    C[, t] <- C_t
    
    # Update rolling of C 
    roll_C_onC <- roll_C_onC + C_t
    roll_C_onE <- roll_C_onE + C_t
    roll_C_onY <- roll_C_onY + C_t
    
    # Generate E (depends on C[t-27, t] and E[1, t-1])
    recent_C_onE <- roll_C_onE > 0
    recent_E_onE <- roll_E_onE > 0
    prob_E <- plogis(log_p_E + log_C_reduce_E*recent_C_onE + log_E_reduce_E*recent_E_onE)
    E_t <- rbinom(n, 1, prob_E)
    E[, t] <- E_t
    
    # Update rolling of E
    roll_E_onE <- roll_E_onE + E_t
    roll_E_onY <- roll_E_onY + E_t
    
    
    # Generate Y (depends on C[t-risk_window+1, t], E[t-risk_window+1, t])
    recent_C_onY <- roll_C_onY > 0
    recent_E_onY <- roll_E_onY > 0

    prob_Y <- plogis(log_baseline_Y + log_IRR_E*recent_E_onY + log_IRR_C*recent_C_onY)
    Y[, t] <- rbinom(n, 1, prob_Y)
    
  }

# Reshape to long format
id <- rep(1:n, each = obs_time)
day <- rep(1:obs_time, times = n)
data_long <- data.frame(
  id = id,
  day = day,
  C = as.vector(t(C)),
  E = as.vector(t(E)),
  Y = as.vector(t(Y))
)
data_long <- as.data.table(data_long)

return(data_long)
}
```

### Function: Reshape data to SCCS-compatible format

```{r}
#Reshape data to SCCS format

SCCS_reformat_confound <- function(data, risk_window = chosen_risk_window){
  Y_data <- data %>%
    .[Y ==1 , .(id, Y_day = day)] %>%
    .[, .row := seq_len(.N), by = id]
  E_data <- data %>%
    .[E ==1 , .(id, E_day = day)] %>%
    .[, .row := seq_len(.N), by = id]
  C_data <- data %>%
    .[C ==1 , .(id, C_day = day)] %>%
    .[, .row := seq_len(.N), by = id]

  merge_E_C <- merge(E_data, C_data, by = c("id", ".row"), all = TRUE)
  merge_Y_E_C <- merge(Y_data, merge_E_C, by = c("id"), all = TRUE)
  
  merge_Y_E_C <- merge_Y_E_C %>%
    .[!is.na(Y_day)] %>%
    .[ , `:=`(obs_start = 1, 
              obs_end = 500,
              E_end = E_day + risk_window - 1,
              C_end = C_day + risk_window - 1)]

  merge_Y_E_C <- as.data.frame(merge_Y_E_C)

  return(merge_Y_E_C)
}

```

### Function: Analyse data

```{r}
analyse_sccs_confound <- function(data, rep)
  {
  # Fit SCCS model
  model <- standardsccs(event ~ E_day + C_day, 
                       indiv= id,         # subject ID
                       astart = obs_start,# start of observation period 
                       aend = obs_end,    # end of observation period 
                       aevent = Y_day,    # event time
                       adrug = cbind(E_day, C_day), # start of exposure
                       aedrug = cbind(E_end, C_end),  # end of risk period
                       expogrp = list(0, 0),       # start of risk period counted from 'adrug'
                       data = data)
  
  # Extract results from SCCS model
  est_E <- coef(model)[1,1]
  se_E <- coef(model)[1,3]
  IRR_E <- exp(est_E)
  IRR_E_CI_Lower <- model$conf.int[1,3]
  IRR_E_CI_Upper <- model$conf.int[1,4]
  est_C <- coef(model)[2,1]
  IRR_C <- coef(model)[2,2]
  IRR_C_CI_Lower <- model$conf.int[2,3]
  IRR_C_CI_Upper <- model$conf.int[2,4]
  n_event <- model$nevent
  res <- data.frame(rep = rep, 
                    est_E, se_E, IRR_E, IRR_E_CI_Lower, IRR_E_CI_Upper, 
                    est_C, IRR_C, IRR_C_CI_Lower, IRR_C_CI_Upper, 
                    n_event, 
                    row.names = NULL)
  return(res)
}
```

### Function: Bias quantification

```{r}
bias_quantification <- function(true_IRR_E, true_IRR_C, result_table)
{
  true_beta1 = log(true_IRR_E)
  true_beta2 = log(true_IRR_C)

  # Number of missing values of estimated beta1 (e.g due to convergence)
  missing_beta1 <- sum(is.na(result_table$est_E))
  
  # bias
  beta_1_hat <- mean(result_table[,"est_E"])
  bias_beta_1 <- beta_1_hat - true_beta1
  
  beta_2_hat <- mean(result_table[,"est_C"])
  bias_beta_2 <- beta_2_hat - true_beta2
  
  # Coverage
  result_table$coverage_IRR_E <- with(result_table,
                                    IRR_E_CI_Lower <= true_IRR_E & IRR_E_CI_Upper >= true_IRR_E)
  coverage_irr_E <- mean(result_table$coverage_IRR_E)
  
  result_table$coverage_IRR_C <- with(result_table,
                                    IRR_C_CI_Lower <= true_IRR_C & IRR_C_CI_Upper >= true_IRR_C)
  coverage_irr_C <- mean(result_table$coverage_IRR_C)  
  
  performance <- data.frame(missing_beta1, bias_beta_1, coverage_irr_E, bias_beta_2, coverage_irr_C)
  
  performance
}
```

### Test the functions

```{r}
set.seed(36)
tic("Cohort simulation, time-varying confounder") # 40 sec
chosen_risk_window <- 28
test <- cohort_time_varying(n = 100000, obs_time = 500, risk_window = chosen_risk_window, 
                               p_C = 1e-3, C_reduce_C = 0.3, 
                               p_E = 3.2e-3, C_reduce_E = 0.25, E_reduce_E = 0.001,
                               baseline_Y = 2e-5, IRR_E = 2, IRR_C = 5) 
toc()
tic("Reformat") # 2 sec
test_reformatted <- SCCS_reformat_confound(test)
toc()
tic("Analyse") # 0.3 sec
analyse_sccs_confound(test_reformatted, rep = 1)
toc()
```

```{r}
set.seed(1997)

n_sim <- 30
chosen_risk_window <- 28
#handlers(global = TRUE)  # Need to run this code in the console instead or RMarkdown

tic("SCCS with time-varying confounder")
rng_states <- list() #Store the state of the random number generator 

with_progress({
  p <- progressor(steps = n_sim)

cohort_1000 <- foreach( i = 1:n_sim, .combine="rbind") %do% {
  rng_states[[i]] <- .Random.seed  # save RNG state
  data <- cohort_time_varying(n = 100000, obs_time = 500, risk_window = chosen_risk_window, 
                               p_C = 1e-3, C_reduce_C = 0.3, 
                               p_E = 3.2e-3, C_reduce_E = 0.25, E_reduce_E = 0.001,
                               baseline_Y = 2e-5, IRR_E = 2.7, IRR_C = 5)
  data_SCCS <- SCCS_reformat_confound(data)
  result<-analyse_sccs_confound(data= data_SCCS, rep = i)
  p(sprintf("Iteration %d", i))  # update progress
  result

}
})
toc()

bias_quantification_result <-bias_quantification(true_IRR_E = 2.7, true_IRR_C = 5, result_table = cohort_1000)
bias_quantification_result <- bias_quantification_result %>%
  mutate(mean_nr_event = mean(cohort_1000$n_event))
bias_quantification_result
```


### Run the full simulation

```{r}
set.seed(2025)

n_sim <- 1000
chosen_risk_window <- 28
#handlers(global = TRUE)  # Need to run this code in the console instead or RMarkdown

tic("SCCS with time-varying confounder")
rng_states <- list() #Store the state of the random number generator 

with_progress({
  p <- progressor(steps = n_sim)

cohort_1000 <- foreach( i = 1:n_sim, .combine="rbind") %do% {
  rng_states[[i]] <- .Random.seed  # save RNG state
  data <- cohort_time_varying(n = 100000, obs_time = 500, risk_window = chosen_risk_window, 
                               p_C = 1e-3, C_reduce_C = 0.3, 
                               p_E = 3.2e-3, C_reduce_E = 0.25, E_reduce_E = 0.001,
                               baseline_Y = 2e-5, IRR_E = 2.7, IRR_C = 5)
  data_SCCS <- SCCS_reformat_confound(data)
  result<-analyse_sccs_confound(data= data_SCCS, rep = i)
  p(sprintf("Iteration %d", i))  # update progress

  result
}
})
toc()

export(cohort_1000, here("Results", "SCCS_results_no_confounder_daily.csv"))
capture.output(rng_states, file = "RNG_states_SCCS_no_confounder_daily.txt")

# Evaluate performance

#Exploratory
#Distribution of effect estimates

hist(cohort_1000$est, breaks = 30, main = "Distribution of beta_1")
hist(cohort_1000$se, breaks = 30, main = "Distribution of SE of beta_1")
hist(cohort_1000$n_event, breaks = 10, main = "Distribution of number of events")

bias_quantification_result <-bias_quantification(true_IRR = 3, result_table = cohort_1000)
bias_quantification_result <- bias_quantification_result %>%
  mutate(mean_nr_event = mean(cohort_1000$n_event))
bias_quantification_result
```


#### Parallel session

```{r}
n_sim <- 1000
chosen_risk_window <- 28

tic("Parallel simulation") # measure run time
# Set up parallel sessions
n_cores <- parallel::detectCores() - 3
cl <- makeCluster(n_cores)
registerDoParallel(cl)
registerDoRNG(1997) 


results_list <- foreach(i = 1:n_sim, 
                        .packages = c("extraDistr", "dplyr", "SCCS", "data.table"),
                        .combine = rbind) %dopar% {
  data <- cohort_time_varying(n = 100000, obs_time = 500, risk_window = chosen_risk_window, 
                               p_C = 1e-3, C_reduce_C = 0.3, 
                               p_E = 3.2e-3, C_reduce_E = 0.25, E_reduce_E = 0.001,
                               baseline_Y = 2e-5, IRR_E = 2.7, IRR_C = 5)
  data_SCCS <- SCCS_reformat_confound(data)
  result<-analyse_sccs_confound(data= data_SCCS, rep = i)
  result
                        }

stopCluster(cl)
toc() # measure run time

export(results_list, here("Results", "SCCS_results_confounder_1000_daily.csv"))

```

